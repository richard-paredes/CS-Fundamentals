HW3 Due 11:59PM April 16

***Please review the top part of ../hw1/hw1.txt***
***Your chance of success greatly increases if you start very early. Your chance of failure increases if you start late. Please use as many reviews as you possibly can.***

1.
According to the article <http://martinfowler.com/bliki/BeckDesignRules.html>, what are the rules of simple design. Why are these important? Discuss the impact of these principles. Give examples of using these principles in the class so far. Also give from examples outside of this class, but limit to your personal experiences.

Following Martin Fowler's interpretation, the rules of simple design, in order of priority, are to ensure the code passes tests, reveals intentions clearly, eliminates duplication, and incorporates only essential elements that preserve the prior three rules. Following the rules of simple design facilitate developers to produce higher quality software with better design. Specifically, each of the rules play a significant role in mitigating, or eliminating altogether, the accidental process of making software overly complex and unmaintainable.

By guaranteeing that the codebase passes all tests, developers are able to demonstrate that the software is useful in solving the intended problem for which it was written -- at least to the extent of the relevant coverage that the test cases provide. A design that fails to adhere to this rule is unable to provide consistent assurance to its clients and, in turn, most likely brittle. Incorporating relevant tests to the software provides robustness and empowers developers to extend and refactor without fear, allowing the code to become more maintainable and evolvable. As the code is modified, the tests serve as a metric of verification which can alert developers of breaking changes. More importantly, as a user of the software, these tests serve as a declaration that the software is relevant and can be used to solve the problem at hand. Guided by Test-Driven Development, this rule has been paramount in every assignment in this class. For example, when reaching the stage of tactical design for every assignment, the implementation logic of every feature was driven by test cases. These tests provided an instant feedback process at every step of the way, verifying whether the specification requirements were satisfied prior to submitting for code reviews. Through this iterative feedback cycle provided by TDD and this rule, the design of every assignment remained robust and contained minimal complexity. Yet beyond the scope of this course, the use of this rule has had a significant impact in my experience working as an intern software developer. Upon initially entering my project, there was extremely low code coverage which resulted in a feeling of fragile, unmaintainable code. Any major changes was risky, and refactoring was nearly impossible. But slowly, as I began incorporating tests when updating the legacy code and incorporating new features, the software began to feel more robust and issues were detected very quickly by our continuous integration process. Although there was a high initial overhead of incorporating more code coverage into the project, adding tests helped solidify my understanding of how the software was being used while also creating a safety net for future changes, ultimately making the entire process a valuable investment.

Having code reveal its intentions plays a vital role in making sure that the software is easier to understand and maintain. Developers have a natural habit of writing code that obfuscates its intentions. Consequently, the code is difficult to understand and debug by other developers, and many of its side-effects remain are hidden, resulting in bugs. By putting the effort of writing code that explicitly declares its objective, developers have an easier time understanding how the code works and are able to quickly identify any potential issues or bugs. The end result is purposeful, cohesive software that reads like a good book. Conveyed by the code reviews for every assignment thus far, keeping the code minimal and easy to understand is a priority. For example, our assignments have incorporated radon to analyze the cyclomatic complexity and prevent the build from succeeding if complexity becomes too high. It has pushed us to become better developers and think more creatively in how we approach software requirements. Even when working with software outside of this class, I focus on making any code I write as readable as possible, often through the use of refactoring and creating separate classes or methods with discrete responsibilities. Building off my previous example as an intern, writing simple code with clear intentions has helped decouple many elements, allowing the code to be more testable. Without a doubt, finding ways to reduce the complexity can sometimes be challenging, but it is necessary to keep the code simple and intuitive.

Similar to the prior rule, removing redundancy in code has great implications in the management and maintainability of software. When changes to the software are required, having duplication present necessitates changing every copy of the repeated code. This process creates room for mistakes, potentially leading to bugs, and also results in software that is more tedious to evolve. Through consolidating the duplication, the likelihood of bugs decreases as the efficiency of development increases. Instead of focusing efforts on identifying every place to make a repeated update, developers can redirect their attention to more fruitful changes to the software. In the context of our assignments so far, duplication is rejected in favor of reusability. A great example of how this rule was applied can be seen in the memoized recursive Fibonacci function of assignment 3. Rather than duplicating the recursion involved, we added extensibility to the base Fibonacci recursive function to allow its reuse in the memoized function. This way, there is a single point of truth for the logic and any updates can automatically cascade as needed. In my other software projects, I have had the opportunity to exercise this rule many times, often through the use of inheritance. For example, I was once working on incorporating multiple learning policies to control the behavior of an autonomous agent for an artificial intelligence project. As I worked on adding these features, I realized all the learning policies shared common logic. Instead of repeating the same logic in every policy, I created an base policy class that contained the shared logic and created additional subclasses for each learning policy that each extended this logic. The end result was extremely simple and cohesive, and made it a painless process later when adding the feature to allow the autonomous agent to switch between policies.  

The final rule of simple design echoes the sentiment of the YAGNI principle. In trying to predict the future by making certain features more extensible, developers often trap themselves into creating software with a burdensome design. Although conceived with good intentions, trying to incorporate features that are not yet required adds unnecessary weight and complexity to the software. Software requirements are often extremely fluid, so there is very little chance that implementing an unnecessary feature does not become obsolete. Rather than wasting effort in anticipating requirements in advance and developing features that will never be used, the design should follow an incremental, minimal approach. This minimizes complexity, eliminates unnecessary effort, and ultimately prevents any issues that would otherwise result from carrying speculative features. 

2. What design patterns did you use in assignment 3? Discuss.

PLEASE REPLACE THIS WITH YOUR RESPONSE
